{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Example Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import rasterio\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_data_from_file(\n",
    "    filename: str,\n",
    "    lon_lat_tuples: list,\n",
    "    queue: multiprocessing.Queue = None,\n",
    "    sub_error_val: float = np.nan,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dictionary of values for the first 3 bands of `filename`,\n",
    "    which is assumed to be an raster file with at least 3 bands in the\n",
    "    epsg4326 coordinate system. This dictionary is intended to be used\n",
    "    as input to create or add to a pandas dataframe, with keys being\n",
    "    the column names and values being the row values.\n",
    "    \n",
    "    :param filename: raster file to extract values from\n",
    "    :param lon_lat_tuples: list of (lon, lat) values in the raster file\n",
    "      to extract values for\n",
    "    :queue: multiprocessing queue; if it is not None, the return value\n",
    "      will be added to it\n",
    "    :sub_error_val: value to return in the dict if the file cannot be\n",
    "      opened due to a RasterioIOError, default is np.nan\n",
    "    :return: dictionary with keys being band indexes and values being\n",
    "      those band's values for each given coordinate\n",
    "    \"\"\"\n",
    "    bands = [1, 2, 3]\n",
    "    # try up to 3 times to get the values\n",
    "    cnt = 0\n",
    "    success = False\n",
    "    while not success and cnt < 3:\n",
    "        try:\n",
    "            d = dict([(f\"band{b}\", []) for b in bands])\n",
    "            # open file\n",
    "            with rasterio.open(filename) as src:\n",
    "                # grab all point values with src.sample; 3 indexes are\n",
    "                # being grabbed for each point, so it will return a list\n",
    "                # of lists (inner lists have length 3)\n",
    "                pt_values = src.sample(lon_lat_tuples, indexes=bands)\n",
    "                for pt_value in pt_values:\n",
    "                    for val, b in zip(pt_value, bands):\n",
    "                        d[f\"band{b}\"].append(val)\n",
    "            # put dict in multiprocessing queue if given one\n",
    "            if queue is not None:\n",
    "                queue.put(d)\n",
    "            success = True\n",
    "        except rasterio.errors.RasterioIOError:\n",
    "            time.sleep(3)\n",
    "            cnt += 1\n",
    "    # if it failed, make the intended dictionary exactly the same as if it\n",
    "    # succeeded, but make all values equal to sub_error_val\n",
    "    if not success :\n",
    "        print(\n",
    "            f\"Failed to open file {filename} because of RasterioIOError,\"\n",
    "            f\"substituting values with {sub_error_val}\"\n",
    "        )\n",
    "        d = dict([(f\"band{b}\", []) for b in bands])\n",
    "        for _ in lon_lat_tuples:\n",
    "            for band in b:\n",
    "                d[f\"band{b}\"].append(sub_error_val)\n",
    "        # put dict in multiprocessing queue if given one\n",
    "        if queue is not None:\n",
    "            queue.put(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values\n",
    "filename = \"s3://jupiter-climatescoreglobal-eos/production/heat/fit_v7/daysExceeding35C/agg_v2/ssp585/remap_v1/2045/n40w075.tif\"\n",
    "lon_lat_tuples = [(-73.946, 40.693), (-73.973, 40.773)]\n",
    "\n",
    "# create dictionary with lon lat data\n",
    "data = {}\n",
    "data[\"lon\"] = [t[0] for t in lon_lat_tuples]\n",
    "data[\"lat\"] = [t[1] for t in lon_lat_tuples]\n",
    "\n",
    "# get point data (print time it took to query)\n",
    "start_time = time.perf_counter()\n",
    "results = point_data_from_file(filename, lon_lat_tuples)\n",
    "print(f\"took {round(time.perf_counter() - start_time, 2)}s to query\")\n",
    "\n",
    "# store results in dict\n",
    "for k, v in results.items():\n",
    "    data[k] = v\n",
    "\n",
    "# display results\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example extraction using multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT:\n",
    "##### !!! jupyter notebooks can only queue up execution of a single cell if that cell uses the multiprocessing library !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values\n",
    "lon_lat_tuples = [(-73.946, 40.693), (-73.973, 40.773)]\n",
    "files_to_query = [\n",
    "    \"s3://jupiter-climatescoreglobal-eos/production/heat/fit_v7/daysExceeding35C/agg_v2/ssp245/remap_v1/2025/n40w075.tif\",\n",
    "    \"s3://jupiter-climatescoreglobal-eos/production/heat/fit_v7/daysExceeding35C/agg_v2/ssp585/remap_v1/2045/n40w075.tif\",\n",
    "]\n",
    "\n",
    "# create out dictionary with lon lat data\n",
    "data = {}\n",
    "data[\"lon\"] = [t[0] for t in lon_lat_tuples]\n",
    "data[\"lat\"] = [t[1] for t in lon_lat_tuples]\n",
    "\n",
    "# get point data using multiprocessing (print time it took to query)\n",
    "queue = multiprocessing.Queue()\n",
    "processes = [\n",
    "    multiprocessing.Process(\n",
    "        target=point_data_from_file,\n",
    "        args=(filename, lon_lat_tuples, queue, np.nan),\n",
    "    )\n",
    "    for filename in files_to_query\n",
    "]\n",
    "# start all the processes before doing anything else\n",
    "start_time = time.perf_counter()\n",
    "for p in processes:\n",
    "     p.start()\n",
    "# call join\n",
    "for p in processes:\n",
    "    p.join()\n",
    "# collect results from the queue\n",
    "results = [queue.get() for p in processes]\n",
    "print(f\"took {round(time.perf_counter() - start_time, 2)}s to query\")\n",
    "\n",
    "# store results in dict\n",
    "for i, result in enumerate(results):\n",
    "    for k, v in result.items():\n",
    "        data[f\"file{i}_{k}\"] = v\n",
    "\n",
    "# display results\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
